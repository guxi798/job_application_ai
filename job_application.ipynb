{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Crew to Tailor Job Applications\n",
    "\n",
    "A multi-agent system that will adjust the provided resume (in markdown format) so it matches the target job description better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path and file name for you resume file, and job posting url here\n",
    "\n",
    "job_posting_url = 'https://job-boards.greenhouse.io/ziprecruiter/jobs/7114545?gh_src=89c6ee071us'\n",
    "job_title = \"Data Scientist\"\n",
    "resume_file = \"./Resume.md\"\n",
    "\n",
    "# set up inputs for the crew\n",
    "job_application_inputs = {\n",
    "    'job_posting_url': job_posting_url,\n",
    "    'job_title': job_title\n",
    "}\n",
    "\n",
    "logfile = './test_log.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m venv .venv\n",
    "#source .crewai_venv/bin/activate\n",
    "#!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 setuptools==80.9.0 litellm==1.77.0\n",
    "#!pip install crewai crewai_tools langchain_community langchain_openai\n",
    "#!export CREWAI_DISABLE_TELEMETRY=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import libraries, APIs and LLM\n",
    "from crewai import Agent, Task, Crew\n",
    "from crewai.utilities.paths import db_storage_path\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from crewai_tools import (\n",
    "  ScrapeWebsiteTool,\n",
    "  SerperDevTool,\n",
    "  FileReadTool,\n",
    "  MDXSearchTool\n",
    ")\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
    "\n",
    "logging.basicConfig(filename=logfile, \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', \n",
    "                    filemode='a')\n",
    "logging.info(f\"Storage location: {db_storage_path()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "from litellm import completion\n",
    "\n",
    "PRICE_PER_1M_CACHE_HIT_INPUT = 0.5  # RMB\n",
    "PRICE_PER_1M_CACHE_MISS_INPUT = 4\n",
    "PRICE_PER_1M_OUTPUT = 12\n",
    "\n",
    "class LoggedLLM(LLM):\n",
    "    def __init__(self, model: str, base_url: str, api_key: str, **kwargs):\n",
    "        super().__init__(model=model, **kwargs)\n",
    "        self.base_url = base_url\n",
    "        self.api_key = api_key\n",
    "        self.usage_totals = {\n",
    "            \"cost\": 0,\n",
    "            \"prompt_cache_hit_tokens\": 0,\n",
    "            \"prompt_cache_miss_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "        }\n",
    "\n",
    "    def call(self, messages: str, **kwargs) -> str:\n",
    "        # Prepare the message for LiteLLM\n",
    "        if isinstance(messages, str):\n",
    "            messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "        \n",
    "        # Call LiteLLM's completion function\n",
    "        response = completion(\n",
    "            model=self.model,\n",
    "            base_url=self.base_url,\n",
    "            api_key=self.api_key,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        # Extract the response content and token usage\n",
    "        content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        usage = response.get(\"usage\", {})\n",
    "        cache_hit_tokens = getattr(usage, \"prompt_cache_hit_tokens\", 0)\n",
    "        cache_miss_tokens = getattr(usage, \"prompt_cache_miss_tokens\", 0)\n",
    "        completion_tokens = getattr(usage, \"completion_tokens\", 0)\n",
    "        total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "\n",
    "        cost = (cache_hit_tokens / 1_000_000 * PRICE_PER_1M_CACHE_HIT_INPUT) +  \\\n",
    "               (cache_miss_tokens / 1_000_000 * PRICE_PER_1M_CACHE_MISS_INPUT) + \\\n",
    "               (completion_tokens / 1_000_000 * PRICE_PER_1M_OUTPUT)\n",
    "\n",
    "        self.usage_totals[\"cost\"] += cost\n",
    "        self.usage_totals[\"prompt_cache_hit_tokens\"] += cache_hit_tokens\n",
    "        self.usage_totals[\"prompt_cache_miss_tokens\"] += cache_miss_tokens\n",
    "        self.usage_totals[\"completion_tokens\"] += completion_tokens\n",
    "        self.usage_totals[\"total_tokens\"] += total_tokens\n",
    "        \n",
    "        # Log the token usage\n",
    "        logging.info(f\"[USAGE] est. cost={cost:.6f}, cache_hit={cache_hit_tokens}, cache_miss={cache_miss_tokens}, completion={completion_tokens}, total={total_tokens}\")\n",
    "\n",
    "        return content\n",
    "\n",
    "# Configure LiteLLM with DeepSeek-R1 model\n",
    "# deepseek_llm = LLM(\n",
    "#     model=\"deepseek/deepseek-chat\",\n",
    "#     base_url=\"https://api.deepseek.com/v1\",\n",
    "#     api_key=os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "# )\n",
    "\n",
    "deepseek_llm = LoggedLLM(\n",
    "    model=\"deepseek-chat\",\n",
    "    base_url=\"https://api.deepseek.com/v1\",\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")\n",
    ")\n",
    "\n",
    "#response = deepseek_llm.call(\"Hello\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {\n",
    "    'provider': 'openai',\n",
    "    'config': {'model': 'text-embedding-3-small'}\n",
    "}\n",
    "\n",
    "# set up crewAI tools\n",
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "read_resume= FileReadTool(resume_file)\n",
    "mdx_tool = MDXSearchTool(mdx=resume_file, \n",
    "#                         config=dict(embedder=embeddings)\n",
    ")\n",
    "\n",
    "#mdx_tool.run(search_query=\"only get work experience\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Crew for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m16:02:46 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:02:50 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:50 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:02:56 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:56 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:03:08 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:08 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:03:14 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:14 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:03:28 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:28 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:03:37 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "chatty = False\n",
    "\n",
    "# Simplified Agent (reusable)\n",
    "test_research = Agent(\n",
    "    role=\"Test Research Agent\",\n",
    "    goal=\"Summarize content briefly.\",\n",
    "    tools=[],\n",
    "    llm=deepseek_llm,\n",
    "    verbose=chatty,\n",
    "    backstory=\"You are a placeholder test research agent.\"\n",
    ")\n",
    "test_profiler = Agent(\n",
    "    role=\"Test Profiler Agent\",\n",
    "    goal=\"Refine and optimize the resume.\",\n",
    "    tools = [read_resume],\n",
    "    llm=deepseek_llm,\n",
    "    verbose=chatty,\n",
    "    backstory=\"You are another placeholder test profiler agent.\"\n",
    ")\n",
    "# Minimal Tasks\n",
    "test_research_task = Task(\n",
    "    description=\"Summarize job posting from {job_posting_url} in 3 bullet points.\",\n",
    "    expected_output=\"3 short bullet points about the job posting.\",\n",
    "    agent=test_research\n",
    ")\n",
    "\n",
    "test_profile_task = Task(\n",
    "    description=\"Summarize resume content in 3 bullet points.\",\n",
    "    expected_output=\"3 short bullet points about the resume.\",\n",
    "    agent=test_profiler,\n",
    "    context=[test_research_task]\n",
    ")\n",
    "\n",
    "test_resume_strategy_task = Task(\n",
    "    description=\"Suggest 2 resume improvements based on job posting + profile.\",\n",
    "    expected_output=\"2 short suggestions.\",\n",
    "    agent=test_profiler,\n",
    "    context=[test_research_task, test_profile_task]\n",
    ")\n",
    "\n",
    "test_interview_preparation_task = Task(\n",
    "    description=\"Generate 2 interview questions based on resume + job posting.\",\n",
    "    expected_output=\"2 questions only.\",\n",
    "    agent=test_research,\n",
    "    context=[test_research_task, test_profile_task, test_resume_strategy_task]\n",
    ")\n",
    "\n",
    "# Test crew\n",
    "simplify_crew = Crew(\n",
    "    agents=[test_research, test_profiler],\n",
    "    tasks=[test_research_task, test_profile_task, test_resume_strategy_task, test_interview_preparation_task],\n",
    "    verbose=chatty,\n",
    "    memory=False,        # turn off memory for test runs\n",
    "    output_log_file=logfile # keep logs for analysis\n",
    ")\n",
    "\n",
    "result = simplify_crew.kickoff(inputs=job_application_inputs)\n",
    "logging.info(f\"[USAGE] My aggregated token usage: {deepseek_llm.usage_totals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatty = False\n",
    "# Agent 1: Researcher\n",
    "researcher = Agent(\n",
    "    role=\"Job Researcher for {job_title}\",\n",
    "    goal=\"Make sure to do amazing analysis on \"\n",
    "         \"job posting to help job applicants. \",\n",
    "         #\"Do not include or echo the raw website content in your answer.\",\n",
    "    tools = [scrape_tool],\n",
    "    llm=deepseek_llm,\n",
    "    verbose=chatty,\n",
    "    backstory=(\n",
    "        \"As a Job Researcher, your prowess in \"\n",
    "        \"navigating and extracting critical \"\n",
    "        \"information from job postings is unmatched.\"\n",
    "        \"Your skills help pinpoint the necessary \"\n",
    "        \"qualifications and skills sought \"\n",
    "        \"by employers, forming the foundation for \"\n",
    "        \"effective application tailoring.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Agent 2: Profiler\n",
    "profiler = Agent(\n",
    "    role=\"Personal Profiler for {job_title}\",\n",
    "    goal=\"Do increditble research on job applicants \"\n",
    "         \"to help them stand out in the job market. \",\n",
    "         #\"Do not include or echo the raw file or website content in your answer.\",\n",
    "    tools = [#scrape_tool, \n",
    "             read_resume],\n",
    "    llm=deepseek_llm,\n",
    "    verbose=chatty,\n",
    "    backstory=(\n",
    "        \"Equipped with analytical prowess, you dissect \"\n",
    "        \"and synthesize information \"\n",
    "        \"from diverse sources to craft comprehensive \"\n",
    "        \"personal and professional profiles, laying the \"\n",
    "        \"groundwork for personalized resume enhancements.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Agent 3: Resume Strategist\n",
    "resume_strategist = Agent(\n",
    "    role=\"Resume Strategist for {job_title}\",\n",
    "    goal=\"Find all the best ways to make a \"\n",
    "         \"resume stand out in the job market. \",\n",
    "         #\"Do not include or echo the raw file or website content in your answer.\",\n",
    "    tools = [#scrape_tool,\n",
    "             read_resume],\n",
    "    llm=deepseek_llm,\n",
    "    verbose=chatty,\n",
    "    backstory=(\n",
    "        \"With a strategic mind and an eye for detail, you \"\n",
    "        \"excel at refining resumes to highlight the most \"\n",
    "        \"relevant skills and experiences, ensuring they \"\n",
    "        \"resonate perfectly with the job's requirements.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Agent 4: Interview Preparer\n",
    "interview_preparer = Agent(\n",
    "    role=\"Interview Preparer\",\n",
    "    goal=\"Create interview questions and talking points \"\n",
    "         \"based on the resume and job requirements. \",\n",
    "         #\"Do not include or echo the raw file or website content in your answer.\",\n",
    "    tools = [read_resume],\n",
    "    llm=deepseek_llm,\n",
    "    verbose=chatty,\n",
    "    backstory=(\n",
    "        \"Your role is crucial in anticipating the dynamics of \"\n",
    "        \"interviews. With your ability to formulate key questions \"\n",
    "        \"and talking points, you prepare candidates for success, \"\n",
    "        \"ensuring they can confidently address all aspects of the \"\n",
    "        \"job they are applying for.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Task for Researcher Agent: Extract Job Requirements\n",
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the job posting URL provided ({job_posting_url}) \"\n",
    "        \"to extract key skills, experiences, and qualifications \"\n",
    "        \"required. Use the tools to gather content and identify \"\n",
    "        \"and categorize the requirements. \"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A structured list of job requirements, including necessary \"\n",
    "        \"skills, qualifications, and experiences.\"\n",
    "    ),\n",
    "    agent=researcher,\n",
    "    async_execution=False\n",
    ")\n",
    "\n",
    "# Task for Profiler Agent: Compile Comprehensive Profile\n",
    "profile_task = Task(\n",
    "    description=(\n",
    "        \"Compile a detailed personal and professional profile. \"\n",
    "        \"Utilize tools to extract and \"\n",
    "        \"synthesize information from these sources.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A comprehensive profile document that includes skills, \"\n",
    "        \"project experiences, contributions, interests, and \"\n",
    "        \"communication style.\"\n",
    "    ),\n",
    "    agent=profiler,\n",
    "    async_execution=False\n",
    ")\n",
    "\n",
    "# Task for Resume Strategist Agent: Align Resume with Job Requirements\n",
    "resume_strategy_task = Task(\n",
    "    description=(\n",
    "        \"Using the profile and job requirements obtained from \"\n",
    "        \"previous tasks, tailor the resume to highlight the most \"\n",
    "        \"relevant areas. Employ tools to adjust and enhance the \"\n",
    "        \"resume content. Make sure this is the best resume even but \"\n",
    "        \"don't make up any information. Update every section, \"\n",
    "        \"inlcuding the initial summary, work experience, skills, \"\n",
    "        \"and education. All to better reflrect the candidates \"\n",
    "        \"abilities and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"An updated resume that effectively highlights the candidate's \"\n",
    "        \"qualifications and experiences relevant to the job.\"\n",
    "    ),\n",
    "    output_file=\"tailored_resume.md\",\n",
    "    context=[research_task, profile_task],\n",
    "    agent=resume_strategist\n",
    ")\n",
    "\n",
    "# Task for Resume Strategist Agent: Create a Cover Letter to Highlight Matches\n",
    "cover_letter_task = Task(\n",
    "    description=(\n",
    "        \"Using the profile and job requirements obtained from \"\n",
    "        \"previous tasks, craft a cover letter to highlight the most \"\n",
    "        \"relevant areas. Employ tools to adjust and enhance the \"\n",
    "        \"letter content, but don't make up any information. \"\n",
    "        \"All to better reflrect the candidates \"\n",
    "        \"abilities and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"An well crafted cover letter that effectively highlights the candidate's \"\n",
    "        \"qualifications and experiences relevant to the job.\"\n",
    "    ),\n",
    "    output_file=\"cover_letter.md\",\n",
    "    context=[research_task, profile_task],\n",
    "    agent=resume_strategist\n",
    ")\n",
    "\n",
    "# Task for Interview Preparer Agent: Develop Interview Materials\n",
    "interview_preparation_task = Task(\n",
    "    description=(\n",
    "        \"Create a set of potential interview questions and talking \"\n",
    "        \"points based on the tailored resume and job requirements. \"\n",
    "        \"Utilize tools to generate relevant questions and discussion \"\n",
    "        \"points. Make sure to use these question and talking points to \"\n",
    "        \"help the candiadte highlight the main points of the resume \"\n",
    "        \"and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A document containing key questions and talking points \"\n",
    "        \"that the candidate should prepare for the initial interview.\"\n",
    "    ),\n",
    "    output_file=\"interview_materials.md\",\n",
    "    context=[research_task, profile_task, resume_strategy_task],\n",
    "    agent=interview_preparer\n",
    ")\n",
    "\n",
    "job_application_crew = Crew(\n",
    "    agents=[researcher,\n",
    "            profiler,\n",
    "            resume_strategist,\n",
    "            interview_preparer],\n",
    "\n",
    "    tasks=[research_task,\n",
    "           profile_task,\n",
    "           resume_strategy_task,\n",
    "           cover_letter_task,\n",
    "           interview_preparation_task],\n",
    "\n",
    "    verbose=chatty,\n",
    "    memory=False,\n",
    "    output_log_file=logfile\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = researcher.kickoff('What are the key requirements for job provided at https://job-boards.greenhouse.io/ziprecruiter/jobs/7114545?gh_src=89c6ee071us')\n",
    "#result = profiler.kickoff('What can you tell me about this job applicant?')\n",
    "#result = resume_strategist.kickoff('Refine the job applicant resume')\n",
    "# result = interview_preparer.kickoff('Prepare 5 interview questions')\n",
    "# print(result.usage_metrics)\n",
    "# print(result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_posting_url = 'https://job-boards.greenhouse.io/ziprecruiter/jobs/7114545?gh_src=89c6ee071us'\n",
    "job_title = \"Data Scientist\"\n",
    "resume_file = \"./Resume.md\"\n",
    "\n",
    "# set up inputs for the crew\n",
    "job_application_inputs = {\n",
    "    'job_posting_url': job_posting_url,\n",
    "    'job_title': job_title\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:04:32 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:32 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:04:38 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:38 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:05:36 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:36 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:06:43 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:43 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:06:50 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:50 - LiteLLM:INFO\u001b[0m: utils.py:3258 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m16:08:01 - LiteLLM:INFO\u001b[0m: utils.py:1260 - Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "### this execution will take a few minutes to run\n",
    "logging.info(\"Running instance for job application strategy\")\n",
    "result = job_application_crew.kickoff(inputs=job_application_inputs)\n",
    "logging.info(f\"[USAGE] My aggregated token usage: {deepseek_llm.usage_totals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dislplay the generated `tailored_resume.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"./tailored_resume.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dislplay the generated `interview_materials.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"./interview_materials.md\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
